{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56215e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AlbertModel, AlbertTokenizer\n",
    "import re\n",
    "import os\n",
    "import requests\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cb7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AlbertTokenizer.from_pretrained(\"Rostlab/prot_albert\", do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ab29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlbertModel.from_pretrained(\"Rostlab/prot_albert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d301ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "edgotype = nx.read_gexf(\"data/y2hEdgotyping/edgotype.gefx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "seqFiles = [pd.read_csv(f\"data/y2hEdgotyping/uniprotScan/sequence_{i}.tsv\",delimiter=\"\\t\") for i in range(6)]\n",
    "\n",
    "uniprotMatches = pd.concat(seqFiles)\n",
    "def mergeWithUniprot(graph):\n",
    "    for node in graph.nodes(data=True):\n",
    "        seq = node[1][\"seq\"]\n",
    "        up = uniprotMatches[(uniprotMatches.Sequence == seq) & \\\n",
    "                            (uniprotMatches.Reviewed == \"reviewed\") & \\\n",
    "                           (uniprotMatches.Organism == \"Homo sapiens (Human)\")]\n",
    "        graph.nodes[node[0]][\"uniprotMatches\"] = up\n",
    "        alphafoldStructures = []\n",
    "        for uniprot_id in graph.nodes[node[0]][\"uniprotMatches\"][\"Entry\"]:\n",
    "            fp = f\"/data/dzeiberg/alphafold/predictions/AF-{uniprot_id}-F1-model_v4.pdb.gz\"\n",
    "            if os.path.isfile(fp):\n",
    "                alphafoldStructures.append(fp)\n",
    "        graph.nodes[node[0]][\"alphafoldStructures\"] = alphafoldStructures\n",
    "    return graph\n",
    "edgotype_x = mergeWithUniprot(edgotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d559f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeMut(seq,mut):\n",
    "    og,loc,var = mut[0],int(mut[1:-1]) - 1,mut[-1]\n",
    "    return seq[:loc] + var + seq[loc+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4e85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences,ensg_ids,substitutions = list(zip(*[(\" \".join(list(makeMut(edgotype_x.nodes(data=True)[e[\"db_ensembl_gene_id_mt\"]][\"seq\"],\n",
    "                                                        e[\"Substitution\"]))),\n",
    "                                   e[\"db_ensembl_gene_id_mt\"],\n",
    "                                   e[\"Substitution\"]) for _,_,e in edgotype_x.edges(data=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences,ensg_ids = list(zip(*[(\" \".join(list(n[\"seq\"])),ensg) for ensg,n in edgotype_x.nodes(data=True)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e2752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [re.sub(r\"[UZOB]\", \"X\", sequence) for sequence in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd4ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353455b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = tokenizer.batch_encode_plus(sequences, add_special_tokens=True, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "attention_mask = torch.tensor(ids['attention_mask']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865823b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "\n",
    "ds = data_utils.TensorDataset(input_ids,attention_mask)\n",
    "loader = data_utils.DataLoader(ds, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acca4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77c1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for (inp_id, inp_att_mask) in tqdm(loader,total=len(loader)):\n",
    "    with torch.no_grad():    \n",
    "        embeddings.append(model(input_ids=inp_id,attention_mask=inp_att_mask)[0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a5d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingsMat = np.concatenate(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b3c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [] \n",
    "for seq_num in range(len(embeddingsMat)):\n",
    "    seq_len = (attention_mask[seq_num] == 1).sum()\n",
    "    seq_emd = embeddingsMat[seq_num][1:seq_len-1]\n",
    "    features.append(seq_emd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5608745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ensg,sub_i,f in zip(ensg_ids,substitutions,features):\n",
    "    fp = f\"/data/dzeiberg/ppi/y2hEdgotyping/protAlbertEmbeddings/{ensg}_{sub_i}.pt\"\n",
    "    print(fp)\n",
    "    torch.save(f,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c5d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_score(e):\n",
    "    score = 0\n",
    "    for med in [\"LWH1_f_\",\"LWH10_f_\", \"LWH25_f_\",\n",
    "                \"LWA_f_\",\"LWAH1_f_\"]:\n",
    "        score +=  e[med+\"wt\"] - e[med+\"mt\"]\n",
    "    return score\n",
    "\n",
    "def calc_label(e):\n",
    "    label = False\n",
    "    for med in [\"LWH1_f_\",\"LWH10_f_\", \"LWH25_f_\",\n",
    "                \"LWA_f_\",\"LWAH1_f_\"]:\n",
    "        label = label or (e[med+\"wt\"] - 2 >= e[med+\"mt\"])\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7110af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b637a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "scores = []\n",
    "labels = []\n",
    "for i,j,edge in edgotype_x.edges(data=True):\n",
    "    db = edge[\"db_ensembl_gene_id_mt\"]\n",
    "    mut = edge[\"Substitution\"]\n",
    "    ad = edge[\"ad_ensembl_gene_id_mt\"]\n",
    "    fi = f\"/data/dzeiberg/ppi/y2hEdgotyping/protAlbertEmbeddings/{db}_{mut}.pt\"\n",
    "    fj = f\"/data/dzeiberg/ppi/y2hEdgotyping/protAlbertEmbeddings/{ad}.pt\"\n",
    "    if os.path.isfile(fi) and os.path.isfile(fj):\n",
    "        files.append((fi,fj))\n",
    "        scores.append(calc_score(edge))\n",
    "        labels.append(calc_label(edge))\n",
    "    else:\n",
    "        print(fi,os.path.isfile(fi),fj,os.path.isfile(fj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d325253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadInst(fi,fj):\n",
    "    Xi = torch.load(fi).mean(0)\n",
    "    Xj = torch.load(fj).mean(0)\n",
    "    return np.multiply(Xi,Xj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f83dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for (fi,fj) in tqdm(files):\n",
    "    X.append(loadInst(fi,fj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cbbd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, LinearRegression,LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874645ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "XMat = np.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a223a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XMat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5b6495",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357ae21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a992ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(4,5,figsize=(12,8),sharex=True)\n",
    "valIndices = []\n",
    "valPreds = []\n",
    "aucs = []\n",
    "for i,(trainInds, valInds) in enumerate(KFold().split(XMat,labels)):\n",
    "    XTrain = XMat[trainInds]\n",
    "    yTrain = labels[trainInds]\n",
    "    tmask = ~np.isnan(yTrain)\n",
    "    XTrain = XTrain[tmask]\n",
    "    yTrain = yTrain[tmask]\n",
    "    XVal = XMat[valInds]\n",
    "    yVal = labels[valInds]\n",
    "    vmask = ~np.isnan(yVal)\n",
    "    XVal,yVal = XVal[vmask],yVal[vmask]\n",
    "#     model = Ridge()\n",
    "    model = LogisticRegression(C=.1,max_iter=1000)\n",
    "#     model = SVC(probability=True)\n",
    "    model.fit(XTrain,yTrain)\n",
    "#     yHat = model.predict(XVal)\n",
    "    yHat = model.predict_proba(XVal)[:,1]\n",
    "#     print(np.mean(np.abs(yVal.ravel() - yHat.ravel())))\n",
    "    aucs.append(roc_auc_score(yVal.ravel(),yHat.ravel()))\n",
    "    print(aucs[-1])\n",
    "    valIndices.append(valInds)\n",
    "    valPreds.append(yHat)\n",
    "    yTHat = model.predict_proba(XTrain)[:,1]\n",
    "    ax[0,i].hist(yTHat[yTrain])\n",
    "    ax[1,i].hist(yTHat[~yTrain])\n",
    "    ax[2,i].hist(yHat[yVal])\n",
    "    ax[3,i].hist(yHat[~yVal])\n",
    "print(np.mean(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af638840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
