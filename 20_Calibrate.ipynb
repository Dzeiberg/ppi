{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cebcbb0",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- z-score normalize WT interactions, then also apply to MT\n",
    "- graph partitioned cross validation\n",
    "- bootstrap MT for PPI pairs    \n",
    "- estimate distributions in projected space (PCA,Autoencoder,etc.)\n",
    " - plot projected space\n",
    "\n",
    "\n",
    "\n",
    "Evaluation:\n",
    "- Does normalization affect prior?\n",
    "- Is there consistency across feature representations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18698b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "edgotype_df = pd.read_csv(\"data/y2hEdgotyping/qY2H_edgotyping_data.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "edgotype_df.clinical_significance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79943c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_df = edgotype_df[edgotype_df.aa_change == \"WT\"]\n",
    "mt_df = edgotype_df[edgotype_df.aa_change != \"WT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_df[[\"db_ensembl_gene_id\",\"db_symbol\",\"ad_ensembl_gene_id\",\"ad_symbol\",\"aa_change\",\"clinical_significance\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7675ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(wt):\n",
    "    scoreColumns = ['LWH1_f', 'LWH10_f', 'LWH25_f', 'LWA_f', 'LWAH1_f']\n",
    "    nameColumns = [\"db_symbol\",\"ad_symbol\",\"aa_change\",\"clinical_significance\"]\n",
    "    mts = mt_df[(mt_df.db_orf_id == wt[\"db_orf_id\"]) & \\\n",
    "                (mt_df.ad_orf_id == wt[\"ad_orf_id\"])]\n",
    "    score_wt = wt[scoreColumns].values.astype(float).reshape((1,-1))\n",
    "    name_wt = wt[nameColumns]\n",
    "    if np.isnan(score_wt).any():\n",
    "        return np.zeros((0,5)),np.zeros((0,5)),[],[]\n",
    "    s_mts = mts[scoreColumns].dropna(axis=0)\n",
    "    score_mts = s_mts.values.astype(float)\n",
    "    if len(s_mts.index):\n",
    "        _,name_mts = zip(*mts.loc[s_mts.index, nameColumns].iterrows())\n",
    "    else:\n",
    "        name_mts = []\n",
    "    return score_wt, score_mts, [name_wt], name_mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e9efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_scores(scores):\n",
    "    encoded = np.zeros((scores.shape[0],25))\n",
    "    for i,s in enumerate(scores):\n",
    "        for j,sj in enumerate(s):\n",
    "            encoded[i,5 * j + int(sj)] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef4012",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODE = False\n",
    "if ENCODE:\n",
    "    dim = 25\n",
    "    penalty='l2'\n",
    "else:\n",
    "    dim = 5\n",
    "    penalty=None\n",
    "score_wt = np.zeros((0,dim))\n",
    "score_mt = np.zeros((0,dim))\n",
    "names_wt = []\n",
    "names_mt = []\n",
    "for wt_id, wt in wt_df.iterrows():\n",
    "    score_wt_i, score_mt_i,name_wt,name_mts = getScores(wt)\n",
    "    assert len(score_mt_i) == len(name_mts)\n",
    "    if ENCODE:\n",
    "        score_wt_i = encode_scores(score_wt_i)\n",
    "        score_mt_i = encode_scores(score_mt_i)\n",
    "    score_wt = np.concatenate((score_wt, score_wt_i))\n",
    "    score_mt = np.concatenate((score_mt,score_mt_i))\n",
    "    names_wt.append(name_wt)\n",
    "    names_mt.append(name_mts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f763c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e305dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da985e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_means = score_wt.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bd1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(wt_means,bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad828482",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((score_wt, score_mt))\n",
    "y = np.concatenate((np.ones(score_wt.shape[0]),\n",
    "                    np.zeros(score_mt.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c72c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "namerecords = list(chain.from_iterable(names_wt + names_mt))\n",
    "names = pd.DataFrame(namerecords,index=range(len(namerecords)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3fefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names.loc[[4484,4485]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b2eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de8883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496cb5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dist_curve\n",
    "from dist_curve.curve_constructor import makeCurve, plotCurve\n",
    "from dist_curve.model import getTrainedEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e318ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getTrainedEstimator(\"/data/dzeiberg/ClassPriorEstimation/model.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bb349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ppi.nnpu import getPosterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = []\n",
    "aucs = []\n",
    "priors = []\n",
    "fig,ax = plt.subplots(2,5,figsize=(12,4),sharex=True,sharey=True)\n",
    "fig2,ax2 = plt.subplots(2,5,figsize=(16,3))\n",
    "for i,(trainInd,testInd) in enumerate(KFold(shuffle=True).split(X,y)):\n",
    "    print(f\"~~~~~~~~~~ Fold {i} ~~~~~~~~~~\")\n",
    "    XTr,yTr = X[trainInd],y[trainInd]\n",
    "    XTe, yTe = X[testInd],y[testInd]\n",
    "    names_Te = names.iloc[testInd]\n",
    "    clf_i = LogisticRegression(penalty=\"l2\")\n",
    "    clf_i.fit(XTr,yTr)\n",
    "#     posScores = clf_i.predict_proba(XTe[yTe == 0])[:,1].reshape((-1,1))\n",
    "#     mixScores = clf_i.predict_proba(XTe[yTe == 1])[:,1].reshape((-1,1))\n",
    "    scores = clf_i.predict_proba(XTe)[:,1]\n",
    "    posScores = scores[yTe == 1].reshape((-1,1))\n",
    "    mixScores = scores[yTe == 0].reshape((-1,1))\n",
    "    auc = roc_auc_score(yTe,scores)\n",
    "    aucs.append(auc)\n",
    "    print(\"AUC: {:.3f}\".format(auc))\n",
    "    n,bins,patches = ax[0,i].hist(posScores,\n",
    "               bins=10,density=True)\n",
    "    _,_,_ = ax[1,i].hist(mixScores,\n",
    "                      bins=bins,density=True,alpha=.5)\n",
    "    ax[0,i].set_title(f\"Fold-{i+1} Positive\")\n",
    "    ax[1,i].set_title(f\"Fold-{i+1} Unlabeled\")\n",
    "    clfs.append(clf_i)\n",
    "    curve_i = makeCurve(posScores,mixScores)\n",
    "    ax2[0,i].plot(np.arange(0,1,.01),\n",
    "                (curve_i - curve_i.min()) / (curve_i.max() - curve_i.min()))\n",
    "    alpha_i = model.predict(curve_i.reshape((1,-1)) / curve_i.sum(),\n",
    "                           verbose=0)[0,0]\n",
    "    print(f\"prior est: {alpha_i:.3f}\")\n",
    "    ax2[0,i].axvline(alpha_i,0,1)\n",
    "    ax2[0,i].set_title(f\"Fold {i+1}\")\n",
    "    priors.append(alpha_i)\n",
    "    train_preds,net_i = getPosterior(XTr,yTr.reshape((-1,1)),alpha_i)\n",
    "    test_preds = net_i.predict(XTe)\n",
    "    \n",
    "    print(names_Te.iloc[np.argsort(test_preds.ravel())][:5])\n",
    "    ax2[1,i].hist(test_preds)\n",
    "print(f\"Average AUC_PU: {np.mean(aucs):.2f}\")\n",
    "print(f\"Average Prior: {np.mean(priors):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40af7f62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
